"""
M-ILEA Semantic Signal Aggregator — v1.0
========================================
Converts raw VulnerabilitySignals into Distinct Vulnerabilities using the
M-ILEA 5-level hierarchy:

    Level 0 — Raw Signal     (keyword match, pattern hit)
    Level 1 — Evidence        (signal + file + line + snippet)
    Level 2 — Technique       (root-cause cluster: same subtype/same file family)
    Level 3 — Weakness        (OWASP category + attack surface)
    Level 4 — Vulnerability   (one per OWASP-ID × root-cause, with aggregated evidence)
    Level 5 — Risk Statement  (contextual risk considering ARA posture)

RULES (from the M-ILEA noise-reduction principles):
    Rule A — Same Root Cause   → merge if same owasp_id + same subtype
    Rule B — Same Technique    → merge if same technique, different class/method
    Rule C — Library-Originated → tag origin=THIRD_PARTY, reduce impact weight

This module NEVER deletes evidence — it only changes how signals are
grouped and presented.
"""

from __future__ import annotations
import re
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple


# ─────────────────────────────────────────────────────────────────────────────
# Evidence Classification — epistemic labels
# ─────────────────────────────────────────────────────────────────────────────
#   MECHANISM_EVIDENCE     — direct security mechanism (SSL pinning, signature check)
#   ENFORCEMENT_EVIDENCE   — anti-tampering, root checks, policy enforcement
#   INDICATIVE_EVIDENCE    — heuristic / behavioural indicator (logging, reflection)
#   CONTEXTUAL_EVIDENCE    — runtime environment check (emulator, root, device state)
#
# Mapping: subtype → evidence_type.  Unmapped subtypes default to INDICATIVE.
# ─────────────────────────────────────────────────────────────────────────────
_EVIDENCE_TYPE_MAP: Dict[str, str] = {
    # ── MECHANISM_EVIDENCE ──────────────────────────────────────────────────
    # SSL / TLS / Pinning
    "ssl_trust_all":                "MECHANISM_EVIDENCE",
    "ssl_custom_trust":             "MECHANISM_EVIDENCE",
    "trust_all_certs":              "MECHANISM_EVIDENCE",
    "hostname_bypass":              "MECHANISM_EVIDENCE",
    "empty_trust_manager":          "MECHANISM_EVIDENCE",
    "cleartext_http":               "MECHANISM_EVIDENCE",
    "cleartext_traffic_allowed":    "MECHANISM_EVIDENCE",
    "cleartext_permitted":          "MECHANISM_EVIDENCE",
    "cleartext_traffic_enabled":    "MECHANISM_EVIDENCE",
    "mixed_content_allowed":        "MECHANISM_EVIDENCE",
    "user_ca_trusted":              "MECHANISM_EVIDENCE",
    # Crypto primitives
    "weak_hash_md5":                "MECHANISM_EVIDENCE",
    "weak_hash_sha1":               "MECHANISM_EVIDENCE",
    "insecure_cipher_ecb":          "MECHANISM_EVIDENCE",
    "deprecated_crypto":            "MECHANISM_EVIDENCE",
    "no_padding":                   "MECHANISM_EVIDENCE",
    "weak_random_seed":             "MECHANISM_EVIDENCE",
    "weak_symmetric_cipher":        "MECHANISM_EVIDENCE",
    # Auth mechanism
    "jwt_no_verify":                "MECHANISM_EVIDENCE",
    "basic_auth_plaintext":         "MECHANISM_EVIDENCE",
    "oauth_implicit_flow":          "MECHANISM_EVIDENCE",
    # Anti-tampering mechanism
    "Package Signature Verification": "MECHANISM_EVIDENCE",
    "DEX Integrity Check":          "MECHANISM_EVIDENCE",
    "Asset Hash Verification":      "MECHANISM_EVIDENCE",
    "Native APK Integrity Check":   "MECHANISM_EVIDENCE",
    # SSL pinning mechanism (ARA)
    "OkHttp CertificatePinner":     "MECHANISM_EVIDENCE",
    "Custom X509TrustManager":      "MECHANISM_EVIDENCE",
    "Custom HostnameVerifier":      "MECHANISM_EVIDENCE",
    "Network Security Config Pinning": "MECHANISM_EVIDENCE",
    "Public Key / Certificate Hash Pinning": "MECHANISM_EVIDENCE",
    # Anti-debug mechanism
    "ptrace-Based Anti-Debug":      "MECHANISM_EVIDENCE",
    "TracerPID Inspection":         "MECHANISM_EVIDENCE",
    "Timing-Based Anti-Debug":      "MECHANISM_EVIDENCE",
    "JDWP Debugger Protocol Detection": "MECHANISM_EVIDENCE",
    "Debugger Connection Check":    "MECHANISM_EVIDENCE",
    "Anti-Attach Prevention":       "MECHANISM_EVIDENCE",
    # Anti-instrumentation mechanism
    "Frida Detection":              "MECHANISM_EVIDENCE",
    "Xposed / LSPosed Framework Detection": "MECHANISM_EVIDENCE",
    "Cydia Substrate Detection":    "MECHANISM_EVIDENCE",
    "Process Memory Map Inspection": "MECHANISM_EVIDENCE",
    "Runtime Memory Scan Loop":     "MECHANISM_EVIDENCE",

    # ── ENFORCEMENT_EVIDENCE ─────────────────────────────────────────────────────
    "Install Source Verification":  "ENFORCEMENT_EVIDENCE",
    "Debug Flag Enforcement":       "ENFORCEMENT_EVIDENCE",
    "Package Name Verification":    "ENFORCEMENT_EVIDENCE",
    "debuggable_enabled":           "ENFORCEMENT_EVIDENCE",
    "allow_backup_enabled":         "ENFORCEMENT_EVIDENCE",
    "exported_component_no_permission": "ENFORCEMENT_EVIDENCE",
    "implicitly_exported_component": "ENFORCEMENT_EVIDENCE",
    "dangerous_permission":         "ENFORCEMENT_EVIDENCE",
    "missing_network_security_config": "ENFORCEMENT_EVIDENCE",
    "debug_override_trust":         "ENFORCEMENT_EVIDENCE",
    "debuggable_flag":              "ENFORCEMENT_EVIDENCE",
    "buildconfig_debug":            "ENFORCEMENT_EVIDENCE",
    "weak_password_policy":         "ENFORCEMENT_EVIDENCE",
    "insecure_token_storage":       "ENFORCEMENT_EVIDENCE",

    # ── INDICATIVE_EVIDENCE ─────────────────────────────────────────────────
    # Logging / debug artefacts
    "log_verbose":                  "INDICATIVE_EVIDENCE",
    "stack_trace_print":            "INDICATIVE_EVIDENCE",
    "sensitive_logging":            "INDICATIVE_EVIDENCE",
    "debug_tool_stetho":            "INDICATIVE_EVIDENCE",
    "strictmode_enabled":           "INDICATIVE_EVIDENCE",
    # Reflection / dynamic loading
    "reflection_enumeration":       "INDICATIVE_EVIDENCE",
    "reflection_classload":         "INDICATIVE_EVIDENCE",
    "dynamic_dex_load":             "INDICATIVE_EVIDENCE",
    "runtime_exec":                 "INDICATIVE_EVIDENCE",
    "Runtime.exec":                 "INDICATIVE_EVIDENCE",
    # Credential indicators
    "hardcoded_password":           "INDICATIVE_EVIDENCE",
    "hardcoded_api_key":            "INDICATIVE_EVIDENCE",
    "hardcoded_secret":             "INDICATIVE_EVIDENCE",
    "hardcoded_token":              "INDICATIVE_EVIDENCE",
    "hardcoded_auth_header":        "INDICATIVE_EVIDENCE",
    "hardcoded_private_key":        "INDICATIVE_EVIDENCE",
    "hardcoded_aws_key":            "INDICATIVE_EVIDENCE",
    "hardcoded_google_key":         "INDICATIVE_EVIDENCE",
    # Data storage indicators
    "sharedprefs_plaintext":        "INDICATIVE_EVIDENCE",
    "world_readable_storage":       "INDICATIVE_EVIDENCE",
    "external_storage_access":      "INDICATIVE_EVIDENCE",
    "sqlite_plaintext":             "INDICATIVE_EVIDENCE",
    "internal_file_plaintext":      "INDICATIVE_EVIDENCE",
    # Input validation indicators
    "webview_js_interface":         "INDICATIVE_EVIDENCE",
    "intent_extra_unvalidated":     "INDICATIVE_EVIDENCE",
    "uri_unvalidated":              "INDICATIVE_EVIDENCE",
    "webview_load_untrusted":       "INDICATIVE_EVIDENCE",
    "webview_eval_js":              "INDICATIVE_EVIDENCE",
    "intent_input_unvalidated":     "INDICATIVE_EVIDENCE",
    "webview_input":                "INDICATIVE_EVIDENCE",
    "js_interface":                 "INDICATIVE_EVIDENCE",
    "implicit_intent_hijack":       "INDICATIVE_EVIDENCE",
    # Supply chain indicators
    "facebook_sdk":                 "INDICATIVE_EVIDENCE",
    "adjust_sdk":                   "INDICATIVE_EVIDENCE",
    "branch_io":                    "INDICATIVE_EVIDENCE",
    "bugsnag":                      "INDICATIVE_EVIDENCE",
    "firebase_crashlytics":         "INDICATIVE_EVIDENCE",
    "appsflyer":                    "INDICATIVE_EVIDENCE",
    "mopub":                        "INDICATIVE_EVIDENCE",
    "no_obfuscation":               "INDICATIVE_EVIDENCE",
    # Privacy indicators
    "device_identifier_access":     "INDICATIVE_EVIDENCE",
    "location_access":              "INDICATIVE_EVIDENCE",
    "advertising_id_access":        "INDICATIVE_EVIDENCE",
    "contacts_access":              "INDICATIVE_EVIDENCE",
    "sms_access":                   "INDICATIVE_EVIDENCE",
    "camera_access":                "INDICATIVE_EVIDENCE",
    "device_id_access":             "INDICATIVE_EVIDENCE",

    # ── CONTEXTUAL_EVIDENCE ──────────────────────────────────────────────
    # Root detection
    "SU Binary Check":              "CONTEXTUAL_EVIDENCE",
    "Magisk Detection":             "CONTEXTUAL_EVIDENCE",
    "RootBeer / Detection Library": "CONTEXTUAL_EVIDENCE",
    "Build Tags Inspection":        "CONTEXTUAL_EVIDENCE",
    "Runtime SU Command Execution": "CONTEXTUAL_EVIDENCE",
    "SELinux State Check":          "CONTEXTUAL_EVIDENCE",
    "SafetyNet / Play Integrity Check": "CONTEXTUAL_EVIDENCE",
    "Superuser APK Detection":      "CONTEXTUAL_EVIDENCE",
    "Root File System Artifacts":   "CONTEXTUAL_EVIDENCE",
    # Emulator detection
    "QEMU / Emulator Artifact Check": "CONTEXTUAL_EVIDENCE",
    "Build Fingerprint Check":      "CONTEXTUAL_EVIDENCE",
    "Genymotion / BlueStacks Detection": "CONTEXTUAL_EVIDENCE",
    "System Property Emulator Check": "CONTEXTUAL_EVIDENCE",
    "Sensor Availability Check":    "CONTEXTUAL_EVIDENCE",
    "Telephony / IMEI Validation":  "CONTEXTUAL_EVIDENCE",
    "NOX / MEmu Emulator Detection": "CONTEXTUAL_EVIDENCE",
    # ALVD (cloning / virtualization)
    "Virtual Filesystem Path Check": "CONTEXTUAL_EVIDENCE",
    "App Clone Framework Detection": "CONTEXTUAL_EVIDENCE",
    "Multi-User UID Anomaly Check": "CONTEXTUAL_EVIDENCE",
    "Application Context Isolation Check": "CONTEXTUAL_EVIDENCE",
}

# ── Third-party path markers ────────────────────────────────────────────────
_LIB_PATH_MARKERS: Tuple[str, ...] = (
    "com/google/", "com/facebook/", "com/appsflyer/",
    "com/adjust/", "com/crashlytics/", "com/bumptech/",
    "okhttp3/", "retrofit2/", "com/squareup/",
    "io/reactivex/", "io/flutter/", "com/unity3d/",
    "org/apache/", "org/json/", "org/webkit/",
    "com/airbnb/", "com/amazonaws/", "com/stripe/",
    "androidx/", "android/support/", "kotlinx/",
    "com/github/", "io/sentry/", "com/datadog/",
    "com/newrelic/", "com/braze/", "com/clevertap/",
    "com/reactnative", "com/swmansion/", "expo/modules/",
)

# Short obfuscated paths (e.g. o/a.smali, b/c/d.smali) that are commonly R8
_OBFUSCATED_RE = re.compile(r"^[a-z]/[a-z0-9]{1,3}(?:/[a-z0-9]{1,3}){0,2}\.smali$", re.IGNORECASE)


def _classify_origin(file_path: str) -> str:
    """Classify a file as APP, THIRD_PARTY, or FRAMEWORK."""
    lo = file_path.lower().replace("\\", "/")
    # Strip workspace prefix up to smali root
    for marker in ("smali/", "smali_classes"):
        idx = lo.find(marker)
        if idx != -1:
            lo = lo[idx:]
            break
    for marker in ("jadx/sources/",):
        idx = lo.find(marker)
        if idx != -1:
            lo = lo[idx + len(marker):]
            break
    if any(lo.startswith(m) or f"/{m}" in lo for m in _LIB_PATH_MARKERS):
        return "THIRD_PARTY"
    if _OBFUSCATED_RE.match(lo):
        return "THIRD_PARTY"
    if lo.startswith("android/") or lo.startswith("java/") or lo.startswith("dalvik/"):
        return "FRAMEWORK"
    return "APP"


def _classify_evidence_type(subtype: str) -> str:
    """Assign an epistemic label to an evidence subtype.

    Returns one of:
        MECHANISM_EVIDENCE     — direct security mechanism
        POLICY_EVIDENCE        — configuration / policy rule
        INDICATIVE_EVIDENCE    — heuristic / behavioural indicator
        CONTEXTUAL_EVIDENCE — runtime environment check
    """
    return _EVIDENCE_TYPE_MAP.get(subtype, "INDICATIVE_EVIDENCE")


# ─────────────────────────────────────────────────────────────────────────────
# Output dataclass
# ─────────────────────────────────────────────────────────────────────────────
@dataclass
class AggregatedVulnerability:
    """One distinct vulnerability = one OWASP-ID × root-cause cluster."""
    owasp_id: str
    title: str
    category: str
    severity: str               # base severity from OWASP metadata

    # Technique details (Level 2)
    techniques: List[str]       # unique subtypes that contributed
    technique_count: int = 0    # len(techniques)

    # Evidence aggregation (Level 1)
    total_evidence: int = 0     # raw signal count
    app_evidence: int = 0
    lib_evidence: int = 0
    evidence_density: float = 0.0   # evidence per technique

    # Contextual severity (Level 5) — filled by ARA filter
    effective_severity: str = ""
    ara_mitigations: List[str] = field(default_factory=list)

    # Best evidence samples (for reviewer layer)
    top_evidence: List[str] = field(default_factory=list)
    affected_files: List[str] = field(default_factory=list)

    # Confidence (max across signals)
    confidence: float = 0.0

    # Description & remediation
    description: str = ""
    remediation: str = ""

    # Full technique breakdown (for auditor layer)
    technique_breakdown: List[Dict[str, Any]] = field(default_factory=list)

    # Evidence classification breakdown (epistemic labels)
    evidence_type_breakdown: Dict[str, int] = field(default_factory=dict)

    def __post_init__(self):
        if not self.effective_severity:
            self.effective_severity = self.severity
        if not self.technique_count:
            self.technique_count = len(self.techniques)
        if self.technique_count > 0 and self.total_evidence > 0:
            self.evidence_density = round(self.total_evidence / self.technique_count, 1)

    def as_dict(self) -> Dict[str, Any]:
        return {
            "owasp_id": self.owasp_id,
            "title": self.title,
            "category": self.category,
            "severity": self.effective_severity,
            "base_severity": self.severity,
            "confidence": self.confidence,
            "description": self.description,
            "remediation": self.remediation,
            "recommendation": self.remediation,
            # Aggregation metadata
            "techniques": self.techniques,
            "technique_count": self.technique_count,
            "total_evidence": self.total_evidence,
            "app_evidence": self.app_evidence,
            "lib_evidence": self.lib_evidence,
            "evidence_density": self.evidence_density,
            "effective_severity": self.effective_severity,
            "ara_mitigations": self.ara_mitigations,
            # Display data
            "evidence": self.top_evidence,
            "affected_files": self.affected_files,
            "signal_count": self.total_evidence,
            # Auditor layer
            "technique_breakdown": self.technique_breakdown,
            # Evidence classification (epistemic labels)
            "evidence_type_breakdown": self.evidence_type_breakdown,
        }


# ─────────────────────────────────────────────────────────────────────────────
# OWASP Metadata (same as orchestrator but centralised)
# ─────────────────────────────────────────────────────────────────────────────
_OWASP_META: Dict[str, Tuple[str, str, str, str, str]] = {
    "M1":  ("IMPROPER_CREDENTIAL_USAGE",
            "Improper Credential Usage",
            "HIGH",
            "Hardcoded or improperly managed credentials in application code.",
            "Remove hardcoded secrets. Use Android Keystore. Rotate exposed credentials."),
    "M2":  ("INADEQUATE_SUPPLY_CHAIN",
            "Inadequate Supply Chain Security",
            "HIGH",
            "Third-party SDK or library introduces known-vulnerable components.",
            "Audit dependencies. Use SCA tools. Pin library versions. Monitor CVEs."),
    "M3":  ("INSECURE_AUTH",
            "Insecure Authentication / Authorization",
            "HIGH",
            "Weak authentication or improper authorisation tokens.",
            "Use strong token algorithms (JWT RS256/EdDSA). Enforce server-side validation."),
    "M4":  ("INSUFFICIENT_IO_VALIDATION",
            "Insufficient Input / Output Validation",
            "MEDIUM",
            "JavaScript interfaces, SQL injection sinks, or XSS vectors present.",
            "Validate all input. Sanitise JavaScript bridge. Use parameterised queries."),
    "M5":  ("INSECURE_COMMUNICATION",
            "Insecure Communication",
            "HIGH",
            "Cleartext traffic, weak TLS configuration, or untrusted CAs.",
            "Enforce TLS 1.2+. Pin certificates. Disable cleartext traffic."),
    "M6":  ("INADEQUATE_PRIVACY_CONTROLS",
            "Inadequate Privacy Controls",
            "HIGH",
            "PII data access with potential network exfiltration.",
            "Minimise PII collection. Encrypt in transit and at rest. Obtain consent."),
    "M7":  ("INSUFFICIENT_BINARY_PROTECTIONS",
            "Insufficient Binary Protections",
            "MEDIUM",
            "Aggregated indicators suggest inadequate binary hardening posture, "
            "potentially facilitating reverse engineering.",
            "Enable ProGuard/R8. Integrate RASP. Enforce code signing at runtime."),
    "M8":  ("SECURITY_MISCONFIGURATION",
            "Security Misconfiguration",
            "MEDIUM",
            "Insecure manifest settings expanding the attack surface.",
            "Disable debuggable/allowBackup in production. Restrict exported components."),
    "M9":  ("INSECURE_DATA_STORAGE",
            "Insecure Data Storage",
            "HIGH",
            "Sensitive data in plaintext SharedPreferences, files, or external storage.",
            "Use EncryptedSharedPreferences or Android Keystore for all sensitive data."),
    "M10": ("INSUFFICIENT_CRYPTOGRAPHY",
            "Insufficient Cryptography",
            "HIGH",
            "Deprecated or broken algorithms (MD5, SHA1, AES/ECB).",
            "Replace with AES/GCM, SHA-256, TLS 1.3. Use authenticated encryption."),
}


# ─────────────────────────────────────────────────────────────────────────────
# Core Aggregation Engine
# ─────────────────────────────────────────────────────────────────────────────
class SemanticAggregator:
    """
    Aggregate raw vulnerability signals into distinct vulnerabilities.

    Input:  List[dict]  — raw signal dicts (from unified_scanner.scan_all)
    Output: List[AggregatedVulnerability]

    The aggregation steps:
    1. Group by owasp_id                (Level 3 → one Weakness per OWASP)
    2. Sub-group by subtype             (Level 2 → Techniques)
    3. Within each technique, classify origin (APP vs THIRD_PARTY)
    4. Build technique breakdown         (for auditor layer)
    5. Apply Rule C weighting            (lib signals get reduced impact)
    6. Select top evidence samples       (for reviewer layer)
    7. Compute final metrics
    """

    def aggregate(
        self,
        signals: List[Dict[str, Any]],
        ara_posture: Optional[Dict[str, Any]] = None,
    ) -> List[AggregatedVulnerability]:
        """Run full aggregation pipeline."""
        if not signals:
            return []

        # Step 1: Group by owasp_id
        by_owasp: Dict[str, List[Dict]] = defaultdict(list)
        for sig in signals:
            if isinstance(sig, dict):
                oid = sig.get("owasp_id", "")
                if oid:
                    by_owasp[oid].append(sig)

        results: List[AggregatedVulnerability] = []

        for owasp_id, group in sorted(by_owasp.items()):
            meta = _OWASP_META.get(owasp_id)
            if not meta:
                continue
            cat, title, base_sev, desc, remed = meta

            # Step 2: Sub-group by subtype (technique)
            by_subtype: Dict[str, List[Dict]] = defaultdict(list)
            for sig in group:
                sub = sig.get("subtype", "unknown")
                by_subtype[sub].append(sig)

            # Step 3-4: Build technique breakdown with origin classification
            techniques: List[str] = []
            technique_breakdown: List[Dict[str, Any]] = []
            total_app = 0
            total_lib = 0
            all_files = set()
            top_evidence: List[str] = []
            max_conf = 0.0

            for subtype, sigs in sorted(by_subtype.items(), key=lambda x: -len(x[1])):
                techniques.append(subtype)

                # Classify each signal's origin
                app_count = 0
                lib_count = 0
                sub_files = set()
                sub_evidence: List[str] = []
                sub_code: List[str] = []

                for s in sigs:
                    origin = _classify_origin(s.get("file", ""))
                    if origin == "THIRD_PARTY":
                        lib_count += 1
                    else:
                        app_count += 1
                    if s.get("file"):
                        sub_files.add(s["file"])
                        all_files.add(s["file"])
                    if s.get("evidence"):
                        for e in s["evidence"][:2]:
                            if e not in sub_evidence:
                                sub_evidence.append(e)
                    if s.get("code") and s["code"] not in sub_code:
                        sub_code.append(s["code"])
                    conf = s.get("confidence", 0)
                    if conf > max_conf:
                        max_conf = conf

                total_app += app_count
                total_lib += lib_count

                # Top evidence: prefer APP-origin evidence
                app_sigs = [s for s in sigs if _classify_origin(s.get("file", "")) != "THIRD_PARTY"]
                evidence_source = app_sigs if app_sigs else sigs
                for s in evidence_source[:3]:
                    if s.get("evidence"):
                        for e in s["evidence"][:1]:
                            if e not in top_evidence:
                                top_evidence.append(e)
                    elif s.get("file") and s.get("line"):
                        ev_str = f"{s['file']}:{s['line']} — {subtype}"
                        if ev_str not in top_evidence:
                            top_evidence.append(ev_str)

                technique_breakdown.append({
                    "subtype": subtype,
                    "signal_count": len(sigs),
                    "app_signals": app_count,
                    "lib_signals": lib_count,
                    "evidence_type": _classify_evidence_type(subtype),
                    "files": sorted(sub_files)[:10],
                    "sample_evidence": sub_evidence[:5],
                    "sample_code": sub_code[:3],
                    "max_confidence": max(s.get("confidence", 0) for s in sigs),
                })

            total_signals = total_app + total_lib

            # Step 5b: Compute evidence classification breakdown
            ev_type_counts: Dict[str, int] = defaultdict(int)
            for tb in technique_breakdown:
                et = tb.get("evidence_type", "INDICATIVE_EVIDENCE")
                ev_type_counts[et] += tb["signal_count"]

            # Step 5c: M1 smart description — soft wording when no real credentials
            _TRUE_CRED_SUBTYPES = {
                "hardcoded_password", "hardcoded_api_key", "hardcoded_secret",
                "hardcoded_private_key", "hardcoded_aws_key", "hardcoded_google_key",
            }
            final_desc = desc
            if owasp_id == "M1" and not (set(techniques) & _TRUE_CRED_SUBTYPES):
                final_desc = (
                    "No hardcoded credentials were found. "
                    "Findings indicate potential token-handling or session-identifier patterns."
                )

            # Step 6: Build the aggregated vulnerability
            av = AggregatedVulnerability(
                owasp_id=owasp_id,
                title=f"{owasp_id} — {title}",
                category=cat,
                severity=base_sev,
                techniques=techniques,
                technique_count=len(techniques),
                total_evidence=total_signals,
                app_evidence=total_app,
                lib_evidence=total_lib,
                confidence=min(0.97, max_conf),
                description=final_desc,
                remediation=remed,
                top_evidence=top_evidence[:10],
                affected_files=sorted(all_files)[:15],
                technique_breakdown=technique_breakdown,
                evidence_type_breakdown=dict(ev_type_counts),
            )

            # Step 7: Apply ARA contextual severity (Rule ARA-filter)
            if ara_posture:
                av.effective_severity, av.ara_mitigations = (
                    self._apply_ara_context(owasp_id, base_sev, ara_posture)
                )

            results.append(av)

        return results

    # ─── ARA Contextual Severity Modifier ────────────────────────────────
    @staticmethod
    def _apply_ara_context(
        owasp_id: str,
        base_severity: str,
        ara: Dict[str, Any],
    ) -> Tuple[str, List[str]]:
        """
        Downgrade severity when ARA protections actively mitigate the risk.

        The vulnerability is NOT removed — only its *contextual* severity
        is adjusted, with full reasoning preserved.
        """
        _SEV_ORDER = ["INFO", "LOW", "MEDIUM", "HIGH", "CRITICAL"]

        def _downgrade(sev: str, steps: int = 1) -> str:
            idx = _SEV_ORDER.index(sev) if sev in _SEV_ORDER else 3
            new_idx = max(0, idx - steps)
            return _SEV_ORDER[new_idx]

        def _is_strong(cat_key: str) -> bool:
            cat = ara.get(cat_key, {})
            if not isinstance(cat, dict):
                return False
            return cat.get("present", False) and (cat.get("confidence", 0) or 0) >= 0.7

        mitigations: List[str] = []
        effective = base_severity

        # M1: Hardcoded creds mitigated by SSL Pinning + Anti-Tampering
        if owasp_id == "M1":
            if _is_strong("SSL_PINNING") and _is_strong("ANTI_TAMPERING"):
                effective = _downgrade(effective, 2)
                mitigations.append("SSL Pinning + Anti-Tampering → credential extraction significantly harder")
            elif _is_strong("SSL_PINNING"):
                effective = _downgrade(effective, 1)
                mitigations.append("SSL Pinning → network credential interception mitigated")

        # M5: Insecure Communication mitigated by SSL Pinning
        elif owasp_id == "M5":
            if _is_strong("SSL_PINNING"):
                effective = _downgrade(effective, 2)
                mitigations.append("SSL Pinning detected → MITM risk substantially reduced")

        # M7: Binary protections mitigated by Anti-Tampering + Anti-Instrumentation
        elif owasp_id == "M7":
            protections = 0
            if _is_strong("ANTI_TAMPERING"):
                protections += 1
                mitigations.append("Anti-Tampering active")
            if _is_strong("ANTI_INSTRUMENTATION"):
                protections += 1
                mitigations.append("Anti-Instrumentation active")
            if _is_strong("ROOT_DETECTION"):
                protections += 1
                mitigations.append("Root Detection active")
            if protections >= 2:
                effective = _downgrade(effective, 2)
                mitigations.append(f"→ {protections}/3 binary protections → risk reduced")
            elif protections == 1:
                effective = _downgrade(effective, 1)

        # M9: Data storage mitigated by Root Detection + Anti-Instrumentation
        elif owasp_id == "M9":
            if _is_strong("ROOT_DETECTION") and _is_strong("ANTI_INSTRUMENTATION"):
                effective = _downgrade(effective, 1)
                mitigations.append("Root Detection + Anti-Instrumentation → physical extraction harder")

        # M10: Crypto weaknesses mitigated by SSL Pinning (for transport crypto)
        elif owasp_id == "M10":
            if _is_strong("SSL_PINNING"):
                effective = _downgrade(effective, 1)
                mitigations.append("SSL Pinning → transport-layer crypto exposure reduced")

        return effective, mitigations

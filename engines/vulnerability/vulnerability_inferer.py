"""
Backward-compatible VulnerabilityInfererV1 shim.

Groups VulnerabilitySignal objects by (owasp_id, category) and produces
VulnerabilityFinding-like objects that also carry the originating signals.
"""

from __future__ import annotations

from collections import defaultdict
from dataclasses import dataclass, field
from typing import List

from .models import VulnerabilitySignal
from .taxonomy import VULNERABILITY_TAXONOMY as OWASP_TAXONOMY, SEVERITY_SCORE


@dataclass
class InferredFinding:
    """A finding produced by VulnerabilityInfererV1 (superset of VulnerabilityFinding)."""
    owasp_id: str
    category: str
    title: str
    severity: str
    confidence: float
    description: str
    recommendation: str
    remediation: str
    subtype: str = ""
    affected_files: List[str] = field(default_factory=list)
    signals: List[VulnerabilitySignal] = field(default_factory=list)
    evidence: List[str] = field(default_factory=list)
    score: float = 0.0

    def __post_init__(self):
        """Auto-compute score = severity_weight × confidence (0-10 scale)."""
        if self.score == 0.0 and self.severity and self.confidence:
            self.score = round(
                SEVERITY_SCORE.get(self.severity, 5.0) * self.confidence, 2
            )

    def as_dict(self) -> dict:
        return {
            "owasp_id": self.owasp_id,
            "category": self.category,
            "title": self.title,
            "severity": self.severity,
            "confidence": self.confidence,
            "score": self.score,
            "description": self.description,
            "recommendation": self.recommendation,
            "remediation": self.remediation,
            "subtype": self.subtype,
            "affected_files": self.affected_files,
            "evidence": self.evidence,
        }


class VulnerabilityInfererV1:
    """Groups signals into findings using the OWASP taxonomy."""

    def infer(self, signals: List[VulnerabilitySignal]) -> List[InferredFinding]:
        buckets: dict[tuple, list] = defaultdict(list)
        for sig in signals:
            buckets[(sig.owasp_id, sig.category)].append(sig)

        findings: List[InferredFinding] = []
        for (owasp_id, category), sigs in buckets.items():
            meta = OWASP_TAXONOMY.get(owasp_id, {})
            confidence = max(s.confidence for s in sigs)
            files = list({s.file for s in sigs if s.file})
            subtypes = list({s.subtype for s in sigs if s.subtype})
            findings.append(InferredFinding(
                owasp_id=owasp_id,
                category=category,
                title=meta.get("title", category),
                severity=meta.get("severity", "MEDIUM"),
                confidence=confidence,
                description=meta.get("description", ""),
                recommendation=meta.get("remediation", ""),
                remediation=meta.get("remediation", ""),
                subtype=subtypes[0] if subtypes else "",
                affected_files=files,
                signals=sigs,
                evidence=[f"{s.file}:{s.line} – {s.subtype}" for s in sigs if s.file],
            ))

        findings.sort(key=lambda f: (
            {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3, "INFO": 4}.get(f.severity, 5),
            -f.confidence,
        ))
        return findings
